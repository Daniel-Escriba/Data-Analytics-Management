{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51fa9326",
      "metadata": {},
      "source": [
        "\n",
        "**Estudiante** : \n",
        "\n",
        "- Escriba Flores, Daniel Agustin\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Primer Caso de Estudio: Predicción Temprana de Diabetes mediante Regresión Logística\n",
        "\n",
        "---\n",
        "\n",
        "## Contexto\n",
        "\n",
        "Se desea construir un modelo predictivo que permita estimar el riesgo de padecer diabetes en función de características relacionadas con la salud de una persona (por ejemplo: presión alta, colesterol alto, actividad física, entre otras).\n",
        "Para ello, se ha utilizado el conjunto de datos CDC Diabetes Health Indicators, disponible en el UCI Machine Learning Repository. Este dataset contiene información de más de 250.000 registros, con variables numéricas y categóricas relacionadas con hábitos y condiciones de salud.\n",
        "\n",
        "La variable objetivo del modelo es binaria:\n",
        "- `0` = No presenta diabetes\n",
        "- `1` = Presenta diabetes\n",
        "\n",
        "Debido a que el número de personas diagnosticadas con diabetes es considerablemente menor al de personas sin diagnóstico, este caso representa un escenario con clases desbalanceadas, frecuente en contextos de medicina preventiva.   \n",
        "\n",
        "---\n",
        "\n",
        "## Preguntas de Análisis e Interpretación\n",
        "\n",
        "1.\t**¿El dataset presenta un problema de desbalance de clases? Justifique su respuesta con base en los porcentajes observados.**\n",
        "\n",
        "  Sí, el dataset presenta un claro desbalance de clases.La distribución muestra que el 86.07% de los registros corresponden a personas sin diabetes (Clase 0) , mientras que solo el 13.93% son casos positivos (Clase 1). Se hace mas  visible con el grafico de Distribucion encontrado\n",
        "\n",
        "  > Esta gran diferencia indica que el modelo puede tener dificultades para aprender patrones asociados a la clase minoritaria, afectando su capacidad predictiva en esa categoría.\n",
        "\n",
        "\n",
        "2.\t**Explique cómo el desbalance de clases afectó al modelo de regresión logística sin SMOTE, especialmente en su capacidad para detectar personas con diabetes.**\n",
        "\n",
        "  Sin SMOTE, el modelo priorizo la clase mayoritaria (0), que son precisamente las personas que no tienen diabetes. Esto se refleja claramente en el bajo recall de la Clase 1 (0.16) , lo que significa que solo identificó correctamente al 16% de los casos reales de diabetes .Aunque el accuracy fue alto (0.86) , este valor es engañoso, ya que solo se enfoca en la clase mayoriyaria. Por eso mismo, el F1-score para la Clase 1 fue muy bajo (0.24) , reflejando una mala combinación entre precisión y recall.\n",
        "  > En resumen, el desbalance provocó que el modelo fallara en detectar la mayoría de los casos de diabetes.\n",
        "\n",
        "3. **Luego de aplicar SMOTE, ¿qué cambios se observan en las métricas para la clase 1 (diabetes)? Comente los beneficios y las posibles consecuencias de este cambio.**\n",
        "\n",
        "  Al aplicar SMOTE, se observa una mejora significativa en el recall para la Clase 1 (de 0.16 a 0.76) , lo que implica que ahora se detecta casi el 76% de los casos reales de diabetes , reduciendo notablemente los falsos negativos .\n",
        "\n",
        "  Sin embargo, esta mejora viene con un costo: la precisión disminuye considerablemente (de 0.53 a 0.31) , lo que genera más falsos positivos (personas sin diabetes clasificadas erróneamente como diabéticas).\n",
        "\n",
        "  Sobre el F1-score este Aumentó ligeramente, pasando de 0.24 a 0.44 , aunque sigue siendo bajo debido al desequilibrio entre precisión y recall.\n",
        "  \n",
        "   > Esto podría traducirse en diagnósticos preliminares incorrectos que generen falsas alarmas, lo que podría requerir revisiones adicionales o exámenes complementarios.\n",
        "\n",
        "4.\t**¿Cuál de los dos modelos considera más apropiado para un contexto de salud pública, en el que es fundamental identificar la mayor cantidad posible de personas con diabetes, aunque se cometan algunos falsos positivos? Justifique su respuesta con base en las métricas.**\n",
        "\n",
        "  Aunque ninguno de los dos modelos alcanza un desempeño óptimo para un uso clínico directo, el modelo con SMOTE resulta más adecuado en un contexto de salud pública donde la detección temprana de diabetes es prioritaria.\n",
        "\n",
        "  Este modelo logra un recall del 0.76 para la clase 1 (diabetes) , lo cual implica que ahora se identifica correctamente al 76% de los casos reales , un gran salto desde el 16% del modelo sin balanceo. Este aumento en el recall es clave para minimizar los falsos negativos , es decir, dejar pasar por alto a personas que sí tienen la enfermedad.\n",
        "\n",
        "  > Aunque  como se observa esto trae como consecuencia un aumento en los falsos positivos , estos pueden gestionarse mediante exámenes adicionales o revisiones médicas, lo cual es preferible a no detectar casos reales. En este tipo de contextos preventivos, detectar más casos potenciales, incluso con algunas alertas falsas, es generalmente más deseable que no detectar los verdaderos casos .\n",
        "\n",
        "\n",
        "5.\t**Explique por qué la métrica de accuracy puede ser engañosa en problemas con clases desbalanceadas. ¿Qué métricas deben priorizarse en este tipo de problemas y por qué?**\n",
        "\n",
        "  Cuando hay desbalanceo en clases, La accuracy puede ser engañosa porque mide la proporción total de predicciones correctas sin distinguir entre tipos de error. Un modelo puede alcanzar un alto accuracy simplemente prediciendo siempre la clase mayoritaria, ignorando completamente la clase minoritaria. Por ejemplo, en nuestro caso, el modelo sin SMOTE tuvo un accuracy de 0.86 , pero solo identificó al 16% de los casos reales de diabetes.\n",
        "\n",
        "  En escenarios desbalanceados, es preferible usar métricas que evalúen el desempeño en cada clase:\n",
        "\n",
        "  - Recall : Mide cuántos verdaderos positivos fueron identificados. Es clave cuando queremos minimizar los falsos negativos .\n",
        "  - Precision : Evalúa cuántas de las predicciones positivas son realmente correctas. Útil para controlar los falsos positivos .\n",
        "  - F1-score : Combina precisión y recall, ofreciendo un equilibrio útil en escenarios desbalanceados.\n",
        "  - AUC-ROC : Evalúa el desempeño global del modelo en distintos umbrales, permitiendo comparar modelos incluso en presencia de desbalance.\n",
        "\n",
        "  Estas métricas ofrecen una visión más realista del comportamiento del modelo, especialmente en la clase minoritaria, lo que es crucial en contextos médicos.\n",
        "\n",
        "  ---\n",
        "\n",
        "  ## Codigos del Primer Caso\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "sGhzohCLsCFk",
        "outputId": "5f01902a-d0a1-4c98-9056-a6a020e9bca5"
      },
      "outputs": [],
      "source": [
        "# Instalar las librerías necesarias\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# 1. CARGA DE DATOS DESDE UCI\n",
        "# -----------------------------\n",
        "\n",
        "# Cargar dataset\n",
        "cdc_diabetes = fetch_ucirepo(id=891)\n",
        "\n",
        "# Extraer variables predictoras (X) y objetivo (y)\n",
        "X = cdc_diabetes.data.features\n",
        "y = cdc_diabetes.data.targets\n",
        "\n",
        "# Fusionar en un solo DataFrame para exploración\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Mostrar primeras filas\n",
        "print(\"Primeras filas del dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# Renombrar variable objetivo si es necesario\n",
        "target_col = y.columns[0]\n",
        "\n",
        "# Visualizar distribución de clases\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=target_col, data=df)\n",
        "plt.title('Distribución de clases (Diabetes)')\n",
        "plt.xlabel('Clase (0 = No Diabetes, 1 = Diabetes)')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()\n",
        "\n",
        "# Porcentajes\n",
        "class_percent = df[target_col].value_counts(normalize=True) * 100\n",
        "print(\"\\nDistribución porcentual de clases:\")\n",
        "print(class_percent)\n",
        "\n",
        "if class_percent.min() < 40:\n",
        "    print(\" Dataset desbalanceado: se recomienda aplicar SMOTE.\")\n",
        "else:\n",
        "    print(\" Las clases están balanceadas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt6H__-YsQ25",
        "outputId": "dfd0ad96-a113-4a16-e31b-f743ae7b7f6d"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 2. PREPROCESAMIENTO\n",
        "# -----------------------------\n",
        "\n",
        "# Escalamiento\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# División entrenamiento/prueba con estratificación\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Tamaño entrenamiento: {X_train.shape}\")\n",
        "print(f\"Tamaño prueba: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "n5WEBqQUsUGe",
        "outputId": "beb7fd14-1238-4138-ba99-5f0abc25d74b"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 3. REGRESIÓN LOGÍSTICA SIN BALANCEO\n",
        "# -----------------------------\n",
        "\n",
        "# Entrenar modelo\n",
        "log_model = LogisticRegression(max_iter=1000)\n",
        "log_model.fit(X_train, y_train)\n",
        "\n",
        "# Predicción\n",
        "y_pred = log_model.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Evaluación SIN SMOTE:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Visualizar matriz\n",
        "ConfusionMatrixDisplay.from_estimator(log_model, X_test, y_test, cmap=\"Blues\")\n",
        "plt.title(\"Matriz de Confusión - Sin SMOTE\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "BEidJsOasfoP",
        "outputId": "f9e21505-b4c9-4d0e-970c-d0132cafe162"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# 4. APLICACIÓN DE SMOTE\n",
        "# -----------------------------\n",
        "\n",
        "# Aplicar SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Entrenar nuevo modelo con datos balanceados\n",
        "log_model_sm = LogisticRegression(max_iter=1000)\n",
        "log_model_sm.fit(X_res, y_res)\n",
        "\n",
        "# Predicción con modelo balanceado\n",
        "y_pred_sm = log_model_sm.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Evaluación CON SMOTE:\")\n",
        "print(confusion_matrix(y_test, y_pred_sm))\n",
        "print(classification_report(y_test, y_pred_sm))\n",
        "\n",
        "# Visualizar matriz\n",
        "ConfusionMatrixDisplay.from_estimator(log_model_sm, X_test, y_test, cmap=\"Purples\")\n",
        "plt.title(\"Matriz de Confusión - Con SMOTE\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2trNqIgOcwF"
      },
      "source": [
        "---\n",
        "\n",
        "# Segundo Caso de Estudio: Árboles de Decisión y Validación (10 puntos)\n",
        "\n",
        "## contexto\n",
        "El dataset CDC Diabetes Health Indicators contiene información de encuestas realizadas por los Centros para el Control y la Prevención de Enfermedades (CDC) en Estados Unidos. Este conjunto de datos tiene como objetivo predecir si una persona tiene o no diabetes basándose en una serie de indicadores de salud, como IMC, edad, nivel de actividad física, presión arterial, entre otros.\n",
        "\n",
        "Se te entrega un fragmento de código donde se entrena un modelo de árbol de decisión para clasificar si una persona padece diabetes o no. Tu tarea es analizar, explicar y comparar cómo cambia su desempeño cuando se le aplica un proceso de búsqueda de hiperparámetros con ` GridSearchCV `.\n",
        "\n",
        "La actividad está dividida en dos partes:\n",
        "\n",
        "  1.\tCódigo base del modelo de árbol de decisión sin ajuste de parámetros\n",
        "  2.\tCódigo con ajuste automático de hiperparámetros utilizando GridSearchCV\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ge-EWi-OqQq"
      },
      "source": [
        "# Instrucciones para desarrollar el caso\n",
        "\n",
        "1.\tAnaliza ambos bloques de código que se te entregan (modelo sin ajustes y modelo con ajuste de hiperparámetros).\n",
        "2.\tExplica con tus propias palabras qué hace cada parte del código. Puedes escribir tus respuestas como un documento en Word, PDF o directamente en el cuaderno de Colab.\n",
        "3.\tAgrega comentarios al código (en las celdas de código o al lado del texto) como si tú fueras el profesor que está explicando a otros.\n",
        "4.\tCompara los resultados obtenidos antes y después del ajuste:\n",
        "  -\t¿Qué métricas cambian?\n",
        "\t- ¿Qué diferencias notas en la estabilidad del modelo?\n",
        "\n",
        "  > `Respuesta en la parte final `\n",
        "\n",
        "5.\tJustifica por qué es importante aplicar una búsqueda de hiperparámetros con GridSearchCV en modelos como el árbol de decisión. Si no entiendes alguna parte, puedes usar herramientas como ChatGPT, Bing o Copilot para ayudarte a comprenderla.\n",
        "\n",
        "  > `Respuesta en la parte final `\n",
        "\n",
        "> Recuerda:\n",
        "  -\tNo se trata de copiar y pegar lo que diga la IA.\n",
        "  - Tu tarea es entender el código y redactar tu propia explicación.\n",
        "\n",
        "---\n",
        "\n",
        "### Interpretacion del bloque\n",
        "\n",
        "El código entrena un modelo de árbol de decisión con profundidad máxima limitada en 4 para prevenir el sobreajuste. entramos el modelo con los datos, para  luego hacer una visualizacion de la estructura completa con `plot_tree`.\n",
        "\n",
        "Sobre el grafico, se puede ver cómo toma decisiones basado en las características del dataset y com solo llego a la profundidad maxima de 4 y como clasifica  si una persona tiene dibetes o no."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "-rg9vgtuHjWC",
        "outputId": "c22bb9d5-4b23-436e-a6b4-ee44d2018eff"
      },
      "outputs": [],
      "source": [
        "# Importar librerías adicionales\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "# -----------------------------------------\n",
        "# 5. ENTRENAMIENTO DEL MODELO DE ÁRBOL\n",
        "# -----------------------------------------\n",
        "\n",
        "# Inicializar el modelo (se puede ajustar max_depth para evitar sobreajuste)\n",
        "\n",
        "# Se fija la semilla (42) para reproducibilidad\n",
        "# Limitamos la profundida maxima a 4 para evitar sobreajuste\n",
        "tree_model = DecisionTreeClassifier(random_state=42, max_depth=4)\n",
        "tree_model.fit(X_train, y_train) #Entrenamos el modelo\n",
        "\n",
        "# Visualización del árbol\n",
        "plt.figure(figsize=(20,10)) # Tamano del grafico\n",
        "plot_tree(tree_model, filled=True, feature_names=X.columns, class_names=[\"No Diabetes\", \"Diabetes\"])\n",
        "plt.title(\"Árbol de Decisión (profundidad=4)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJwzTrt8DI1h"
      },
      "source": [
        "---\n",
        "\n",
        "### Interpretacion del bloque\n",
        "\n",
        "Este bloque evalúa el desempeño del árbol de decisión en el conjunto de test mediante la matriz de confusión y el reporte de clasificación , que incluye métricas como `precisión`, `recall` y `f1-score` por clase.\n",
        "\n",
        "Se muestra gráficamente cómo se distribuyen los verdaderos y falsos positivos/negativos, lo cual permite analizar el equilibrio entre aciertos y errores del modelo.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "id": "tep5e_lQHpIY",
        "outputId": "d1803ec5-bbdc-47ca-c6f0-d7c7a6b1a233"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# 6. EVALUACIÓN DEL MODELO EN TEST\n",
        "# -----------------------------------------\n",
        "\n",
        "# Predicciones del modelo\n",
        "y_pred_tree = tree_model.predict(X_test) # en el conjunto de prueba\n",
        "\n",
        "# Matriz de confusión\n",
        "print(\"Matriz de Confusión:\")\n",
        "cm = confusion_matrix(y_test, y_pred_tree)\n",
        "print(cm)  # Compara las etiquetas reales vs la predichas\n",
        "\n",
        "# Visualización de la matriz de confusion\n",
        "ConfusionMatrixDisplay(cm, display_labels=[\"No Diabetes\", \"Diabetes\"]).plot(cmap=\"Greens\")\n",
        "plt.title(\"Matriz de Confusión - Árbol de Decisión\")\n",
        "plt.show()\n",
        "\n",
        "# Reporte detallado\n",
        "print(\"Reporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_tree))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t9ca8JvF09U"
      },
      "source": [
        "---\n",
        "\n",
        "### Interpretacion del bloque\n",
        "\n",
        "Este bloque realiza una validación cruzada de 4 pliegues para medir la estabilidad y generalización del modelo usando el `F1-score macro` , lo cual da relevancia equitativa a ambas clases. Los resultados muestran el desempeño promedio y su variabilidad entre pliegues, lo que permite identificar si el modelo se comporta consistentemente o necesita ajustes. Una baja desviación estándar indica confianza en el modelo; de lo contrario, se sugiere explorar optimización de parámetros o selección de características.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dILmCa4kHsco",
        "outputId": "d8743092-1bee-492c-94dd-d73792cdb360"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# 7. VALIDACIÓN CRUZADA\n",
        "# -----------------------------------------\n",
        "\n",
        "# Aplicar validación cruzada de 4 pliegues\n",
        "scores = cross_val_score(tree_model, X_scaled, y, cv=4, scoring='f1_macro')  # F1-score macro para evaluar el balance entre ambas clases\n",
        "\n",
        "#  Impresion de los Resultados\n",
        "print(\"Resultados de Validación Cruzada (F1-score macro):\")\n",
        "print(f\"Scores individuales por pliegue: {scores}\")\n",
        "print(f\"Promedio del F1-score: {np.mean(scores):.4f}\")\n",
        "print(f\"Desviación estándar: {np.std(scores):.4f}\")\n",
        "\n",
        "# Interpretación sugerida\n",
        "if np.std(scores) < 0.02: # Umbral de estabilidad\n",
        "    print(\"El modelo muestra buena estabilidad entre los pliegues.\")\n",
        "else:\n",
        "    print(\"El modelo podría ser inestable: considera ajustar hiperparámetros o validar la selección de variables.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V6ukOY6IxTO"
      },
      "source": [
        "---\n",
        "\n",
        "### Interpretacion del bloque\n",
        "\n",
        "Explorando vemos que el código utiliza `GridSearchCV` para buscar automáticamente la mejor combinación de hiperparámetros del árbol de decisión, evaluando distintas profundidades, mínimos de división y manejo de desbalance. La métrica usada es el `F1-score macro` y se aplica una validación cruzada de 5 pliegues para asegurar robustez. El resultado es un modelo optimizado que mejora su capacidad de generalización frente al modelo inicial sin ajuste, por tal motivo lo llamamos `best_tree_model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c7bJu9FIwaR",
        "outputId": "825a5c94-bb77-45e9-ef4b-59dbed8a63fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir el modelo base sin ningun ajuste\n",
        "base_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Definir el espacio de búsqueda de hiperparámetros\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 9, None], # Profundidad máxima del árbol\n",
        "    'min_samples_split': [2, 5, 10], # Mínimo de muestras para dividir un nodo\n",
        "    'class_weight': [None, 'balanced'] # Manejo de desbalanceo entre clases\n",
        "}\n",
        "\n",
        "# Buscar la mejor combinación de hiperparámetros\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=base_tree,   # colocamos el modelo base\n",
        "    param_grid=param_grid, # Los hiperparametos\n",
        "    scoring='f1_macro',    # Métrica de evaluación\n",
        "    cv=5,                  # Número de pliegues en validación cruzada\n",
        "    n_jobs=-1              # Usar todos los núcleos disponibles\n",
        ")\n",
        "\n",
        "# Entrenar la búsqueda\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Mejor combinación encontrada\n",
        "print(\"Mejores hiperparámetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Extraer el mejor modelo encontrado\n",
        "best_tree_model = grid_search.best_estimator_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCiE1DJ3KgWr"
      },
      "source": [
        "---\n",
        "\n",
        "### Interpretacion del bloque\n",
        "\n",
        "Este bloque vuelve a aplicar la validación cruzada , pero ahora con el modelo optimizado tras el ajuste de hiperparámetros. Permite comparar si la búsqueda automática mejoró realmente el desempeño del modelo, evaluando el `F1-score macro promedio` y su estabilidad entre pliegues. De esta forma, se verifica si el nuevo modelo es más robusto y equilibrado que el original, especialmente para predecir ambas clases en un contexto médico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtvuzU3OIzgr",
        "outputId": "93818d47-e56c-495a-b0bf-55cd03a0f020"
      },
      "outputs": [],
      "source": [
        "# Validación cruzada con el mejor árbol\n",
        "best_scores = cross_val_score(best_tree_model, X_scaled, y, cv=5, scoring='f1_macro')\n",
        "\n",
        "print(\"\\nValidación cruzada con modelo ajustado:\")\n",
        "print(f\"F1 macro (por pliegue): {best_scores}\")\n",
        "print(f\"F1 promedio: {np.mean(best_scores):.4f}\")\n",
        "print(f\"Desviación estándar: {np.std(best_scores):.4f}\")\n",
        "\n",
        "if np.std(best_scores) < 0.02:\n",
        "    print(\"El modelo ajustado muestra buena estabilidad.\")\n",
        "else:\n",
        "    print(\"El modelo sigue siendo inestable: considerar más técnicas como selección de variables o ensambles.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT3Xyjh8BvBX"
      },
      "source": [
        "---\n",
        "\n",
        "## 4.Compara los resultados obtenidos antes y después del ajuste:\n",
        "-\t¿Qué métricas cambian?\n",
        "- ¿Qué diferencias notas en la estabilidad del modelo?\n",
        "\n",
        "  Con el ajuste se puede observar que  la métrica que muestra una mejora más clara es el F1-score macro , que pasó de un promedio de 0.5258 a 0.6141. Esto indica un mejor equilibrio entre precisión y recall, especialmente para la clase minoritaria (diabetes), gracias al uso de `'class_weight': 'balanced'`, que ayuda a dar mayor relevancia a esta clase durante el entrenamiento.\n",
        "\n",
        "  Sobre la estabilidad, tambien hay diferencias, pues a diferencia del primer modelo el ajustado presenta buena estabilidad, ya que la desviación estándar bajó considerablemente de 0.0636 a 0.0076 , lo que refleja que el modelo ahora tiene un comportamiento mucho más consistente entre los distintos pliegues de validación. Este valor está por debajo de 0.02 , un umbral comúnmente usado como referencia para considerar que un modelo tiene buena estabilidad.\n",
        "\n",
        "\n",
        "## 5.\tJustifica por qué es importante aplicar una búsqueda de hiperparámetros con GridSearchCV en modelos como el árbol de decisión.\n",
        "\n",
        "> Si no entiendes alguna parte, puedes usar herramientas como ChatGPT, Bing o Copilot para ayudarte a comprenderla.\n",
        "\n",
        "  La búsqueda de hiperparámetros mediante GridSearchCV es especialmente valiosa en modelos como el árbol de decisión, ya que permite encontrar automáticamente la combinación óptima de parámetros, como la profundidad máxima del árbol, el número mínimo de muestras para dividir un nodo o cómo se maneja el desbalance de clases puede mejorar significativamente el rendimiento final.\n",
        "\n",
        "  En  nuestro cas, el proceso identificó como mejores parámetros los siguientes:\n",
        "  - uso de balanceo de clases (class_weight igual a 'balanced'),\n",
        "  - profundidad máxima del árbol igual a 7 (max_depth=7)\n",
        "  - un mínimo de 2 muestras para dividir un nodo (min_samples_split=2).\n",
        "  \n",
        "  Estos valores permitieron que el modelo lograra un mejor equilibrio entre precisión y recall.\n",
        "\n",
        "---\n",
        "\n",
        "# Conclusion Extra\n",
        "\n",
        "Ajustar el árbol de decisión permitió mejorar su capacidad para detectar casos de diabetes sin descuidar la estabilidad del modelo. La búsqueda automatizada de hiperparámetros ayudó a encontrar una solución más equilibrada y generalizable. Validar con diferentes pliegues mostró que el modelo ahora responde de manera más consistente ante nuevos datos. En total, se logró un enfoque más sólido para un problema donde no se puede fallar en identificar riesgos reales. La interpretación activa de los resultados, apoyada por herramientas de IA, también resulta ( de manera personal)  ser valiosa para comprender el comportamiento del modelo y afianzar el aprendizaje práctico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "30ae9ca8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metadatos actualizados en Practica_calificada2_Describa.ipynb\n"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "\n",
        "# Cargar el notebook\n",
        "notebook_path = 'Practica_calificada2_Describa.ipynb'\n",
        "nb = nbformat.read(notebook_path, as_version=4)\n",
        "\n",
        "# Actualizar metadatos\n",
        "if 'latex_metadata' not in nb.metadata:\n",
        "    nb.metadata['latex_metadata'] = {}\n",
        "\n",
        "nb.metadata['latex_metadata']['title'] = 'Práctica Calificada 2'\n",
        "nb.metadata['latex_metadata']['author'] = 'Tu Nombre'\n",
        "nb.metadata['latex_metadata']['date'] = '\\\\today'  # Fecha actual en LaTeX\n",
        "\n",
        "# Guardar el notebook\n",
        "nbformat.write(nb, notebook_path)\n",
        "print(f\"Metadatos actualizados en {notebook_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
