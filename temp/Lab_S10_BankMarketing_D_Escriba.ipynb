{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlBEK-jxPElT"
      },
      "source": [
        "# LABORATORIO: An√°lisis Comparativo de √Årboles de Decisi√≥n y M√©todos de Ensamblado en Campa√±as de Marketing Bancario\n",
        "\n",
        "# Introducci√≥n al caso\n",
        "\n",
        "En el contexto actual de digitalizaci√≥n financiera, los bancos buscan optimizar sus campa√±as de marketing directo para aumentar la tasa de conversi√≥n de sus productos. Este laboratorio simula el rol de un analista de datos en una instituci√≥n financiera que busca predecir si un cliente contratar√° un dep√≥sito a plazo fijo a partir de sus caracter√≠sticas personales, historial financiero y comportamiento previo con el banco.\n",
        "\n",
        "Se utilizar√° el dataset Bank Marketing, proveniente de campa√±as telef√≥nicas reales realizadas en Portugal, y se pondr√° en pr√°ctica una comparaci√≥n entre modelos de √°rboles de decisi√≥n simples ydiferentes m√©todos de ensamblado.\n",
        "\n",
        "# Objetivos del laboratorio\n",
        "\n",
        "‚Ä¢ Preprocesar adecuadamente un conjunto de datos mixto (num√©rico y categ√≥rico).\n",
        "‚Ä¢ Entrenar y comparar modelos de clasificaci√≥n basados en √°rboles de decisi√≥n y ensamblado.\n",
        "‚Ä¢ Aplicar t√©cnicas de evaluaci√≥n apropiadas para contextos de desbalance de clases.\n",
        "‚Ä¢ Interpretar los resultados obtenidos desde un enfoque t√©cnico y comercial.\n",
        "‚Ä¢ Reflexionar sobre la aplicabilidad, limitaciones y √©tica del uso de modelos automatizados en\n",
        "decisiones comerciales.\n",
        "\n",
        " # Preparacion de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oll2aeTNe3I3"
      },
      "source": [
        "## Bank Marketing\n",
        "\n",
        "\n",
        "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable `y`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ywneN0qdP8K",
        "outputId": "74b22b79-f634-4d71-d590-68340932e7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# 1. IMPORTACI√ìN DE LIBRER√çAS\n",
        "# =============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wnM-qtkdz0O",
        "outputId": "e0b51c2b-1cbc-4168-9eec-b5fec88f17da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribuci√≥n de clases (no = no se suscribe, yes = si se suscribe):\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "y\n",
            "no     0.883015\n",
            "yes    0.116985\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "\n",
            "Mapeo para job: {'admin.': np.int64(0), 'blue-collar': np.int64(1), 'entrepreneur': np.int64(2), 'housemaid': np.int64(3), 'management': np.int64(4), 'retired': np.int64(5), 'self-employed': np.int64(6), 'services': np.int64(7), 'student': np.int64(8), 'technician': np.int64(9), 'unemployed': np.int64(10), 'unknown': np.int64(11)}\n",
            "Mapeo para marital: {'divorced': np.int64(0), 'married': np.int64(1), 'single': np.int64(2)}\n",
            "Mapeo para education: {'primary': np.int64(0), 'secondary': np.int64(1), 'tertiary': np.int64(2), 'unknown': np.int64(3)}\n",
            "Mapeo para default: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para housing: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para loan: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para contact: {'cellular': np.int64(0), 'telephone': np.int64(1), 'unknown': np.int64(2)}\n",
            "Mapeo para month: {'apr': np.int64(0), 'aug': np.int64(1), 'dec': np.int64(2), 'feb': np.int64(3), 'jan': np.int64(4), 'jul': np.int64(5), 'jun': np.int64(6), 'mar': np.int64(7), 'may': np.int64(8), 'nov': np.int64(9), 'oct': np.int64(10), 'sep': np.int64(11)}\n",
            "Mapeo para poutcome: {'failure': np.int64(0), 'other': np.int64(1), 'success': np.int64(2), 'unknown': np.int64(3)}\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# 2. CARGA DE DATOS\n",
        "# ===========================================\n",
        "\n",
        "# Cargar dataset desde ucirepo\n",
        "# fetch dataset\n",
        "bank_marketing = fetch_ucirepo(id=222)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = bank_marketing.data.features\n",
        "y = bank_marketing.data.targets\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Ver distribuci√≥n de clases\n",
        "print(\"\\nDistribuci√≥n de clases (no = no se suscribe, yes = si se suscribe):\")\n",
        "print(df['y'].value_counts())\n",
        "print(\"\\n\")\n",
        "print(df['y'].value_counts(normalize=True))\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# 4. PREPROCESAMIENTO\n",
        "# ===========================\n",
        "\n",
        "# Guardamos \"y\" como objetivo\n",
        "y = df['y'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "# Eliminamos y del DataFrame para procesar solo caracter√≠sticas\n",
        "X = df.drop(columns=['y'])\n",
        "\n",
        "#En base al laboratorio anterior, Eliminamos por irrelevancia o sesgo predictivo:\n",
        "#day_of_week: poco predictivo\n",
        "#duration: muy predictiva pero solo se conoce despu√©s de llamar , por lo tanto, para un modelo realista, debe eliminarse\n",
        "\n",
        "X = X.drop(columns=['day_of_week', 'duration'], errors='ignore')\n",
        "\n",
        "# Identificamos las columnas categ√≥ricas\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Primero, vamos a manejar los valores NaN en columnas categ√≥ricas\n",
        "# Podemos reemplazarlos con 'unknown' o la moda\n",
        "for col in categorical_columns:\n",
        "    X[col] = X[col].fillna('unknown')\n",
        "\n",
        "# Aplicamos Label Encoding a todas las columnas categ√≥ricas\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "    label_encoders[column] = le\n",
        "    print(f\"Mapeo para {column}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
        "\n",
        "# Manejamos los valores NaN en columnas num√©ricas\n",
        "numeric_columns = X.select_dtypes(include=['number']).columns.tolist()\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X[numeric_columns] = imputer.fit_transform(X[numeric_columns])\n",
        "\n",
        "# Detectar autom√°ticamente las categ√≥ricas (ya excluimos 'y')\n",
        "cat_vars = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Definir el preprocesador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_vars),\n",
        "        # Puedes agregar escalado si lo necesitas m√°s adelante\n",
        "    ],\n",
        "    remainder='passthrough'  # deja pasar otras columnas sin cambios\n",
        ")\n",
        "\n",
        "# Aplicar transformaci√≥n\n",
        "X_encoded = preprocessor.fit_transform(X)\n",
        "\n",
        "# Estandarizar los datos: necesario porque las variables tienen diferentes escalas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Divisi√≥n entrenamiento-prueba con estratificaci√≥n (mantiene proporci√≥n de clases)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzYCEvV3_bfs"
      },
      "source": [
        "---\n",
        "\n",
        "# Preguntas para desarrollo\n",
        "\n",
        "## √Årboles de Decisi√≥n\n",
        "\n",
        "### ¬øQu√© criterio de divisi√≥n (gini, entropy) ofrece mejor precisi√≥n, recall o F1-score en este caso?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxEdDsDhLffq",
        "outputId": "ee12a066-d7b4-4f49-863b-cb02a4839165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üå≥ COMPARACI√ìN DE CRITERIOS DE DIVISI√ìN\n",
            "==================================================\n",
            "üìä Criterio GINI:\n",
            "   Precisi√≥n: 0.8583\n",
            "   Recall: 0.6923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.93      0.91      0.92      7985\n",
            "         yes       0.41      0.48      0.44      1058\n",
            "\n",
            "    accuracy                           0.86      9043\n",
            "   macro avg       0.67      0.69      0.68      9043\n",
            "weighted avg       0.87      0.86      0.86      9043\n",
            "\n",
            "\n",
            "üìä Criterio ENTROPY:\n",
            "   Precisi√≥n: 0.8628\n",
            "   Recall: 0.6882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.93      0.92      0.92      7985\n",
            "         yes       0.42      0.46      0.44      1058\n",
            "\n",
            "    accuracy                           0.86      9043\n",
            "   macro avg       0.67      0.69      0.68      9043\n",
            "weighted avg       0.87      0.86      0.87      9043\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üå≥ COMPARACI√ìN DE CRITERIOS DE DIVISI√ìN\n",
        "# ==========================================\n",
        "\n",
        "criterios = ['gini', 'entropy']\n",
        "modelos = {}\n",
        "\n",
        "print(\"\\nüå≥ COMPARACI√ìN DE CRITERIOS DE DIVISI√ìN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for criterio in criterios:\n",
        "    modelo = DecisionTreeClassifier(\n",
        "        criterion=criterio,\n",
        "        max_depth=8,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    modelos[criterio] = modelo\n",
        "\n",
        "    print(f\"üìä Criterio {criterio.upper()}:\")\n",
        "    print(f\"   Precisi√≥n: {accuracy:.4f}\")\n",
        "    print(f\"   Recall: {recall:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"no\", \"yes\"]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Mt4Ob9_-zU"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Precisi√≥n:\n",
        "- ENTROPY ofrece una mejor precisi√≥n general (0.8628) en comparaci√≥n con GINI (0.8583). Aunque la diferencia es peque√±a, ENTROPY tiene una ligera ventaja en la precisi√≥n general del modelo.\n",
        "\n",
        "Recall:\n",
        "- GINI tiene un mejor recall general (0.6923) en comparaci√≥n con ENTROPY (0.6882). Sin embargo, en detalle, para la clase \"yes\" (suscripciones logradas), ENTROPY tiene un recall de 0.46, mientras que GINI tiene un recall de 0.48. Esto indica que ambos criterios tienen dificultades para detectar bien la clase \"yes\", aunque GINI es ligeramente mejor en este aspecto.\n",
        "\n",
        "F1-score:\n",
        "- El F1-score ponderado es muy similar entre ambos criterios, con ENTROPY ligeramente mejor (0.87) en comparaci√≥n con GINI (0.86). Esto confirma que el equilibrio entre precisi√≥n y recall es similar en ambos casos.\n",
        "\n",
        "**Conclusi√≥n:**\n",
        "\n",
        "Si bien ambos criterios de divisi√≥n (GINI y ENTROPY) ofrecen resultados muy similares, ENTROPY tiene una ligera ventaja en t√©rminos de precisi√≥n general y F1-score ponderado. Sin embargo, GINI tiene un mejor recall general, aunque la diferencia es m√≠nima.\n",
        "\n",
        "En general, ninguno de los criterios alcanza un estado √≥ptimo, especialmente en la detecci√≥n de la clase \"yes\". Por lo tanto, aunque ENTROPY tiene una ligera ventaja en precisi√≥n y F1-score, ambos criterios necesitan mejorar para alcanzar una optimizaci√≥n mejor en la detecci√≥n de ambas clases.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Analiza el √°rbol obtenido: ¬øqu√© variables aparecen como m√°s importantes? ¬øSon coherentes con el contexto del marketing bancario?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaG-laQ8NB9G",
        "outputId": "9fb47802-7cc4-47ad-d0a6-d97eff240825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Variables m√°s importantes seg√∫n el √°rbol GINI:\n",
            "   Variable  Importancia\n",
            "8   contact     0.272957\n",
            "9     month     0.201860\n",
            "11    pdays     0.144226\n",
            "6   housing     0.113830\n",
            "0       age     0.086976\n",
            "\n",
            "üîç Variables m√°s importantes seg√∫n el √°rbol ENTROPY:\n",
            "   Variable  Importancia\n",
            "8   contact     0.249110\n",
            "9     month     0.195391\n",
            "11    pdays     0.151103\n",
            "6   housing     0.100921\n",
            "0       age     0.083624\n"
          ]
        }
      ],
      "source": [
        "for criterio in criterios:\n",
        "    modelo = modelos[criterio]\n",
        "\n",
        "    # Obtener importancias de las variables del modelo entrenado\n",
        "    importancias = modelo.feature_importances_\n",
        "\n",
        "    # Crear un DataFrame con nombres de las variables e importancias\n",
        "    importancias_df = pd.DataFrame({\n",
        "        'Variable': X.columns,\n",
        "        'Importancia': importancias\n",
        "    }).sort_values(by='Importancia', ascending=False)\n",
        "\n",
        "    # Mostrar las 5 variables m√°s importantes\n",
        "    print(f\"\\nüîç Variables m√°s importantes seg√∫n el √°rbol {criterio.upper()}:\")\n",
        "    print(importancias_df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R2EJzPWHHvf"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Las variables m√°s importantes seg√∫n los √°rboles GINI y ENTROPY son consistentes con el contexto del marketing bancario. Estas variables reflejan aspectos clave que pueden influir en la respuesta de los clientes a una campa√±a de marketing:\n",
        "\n",
        "- Tipo de contacto: Importante para la efectividad de la comunicaci√≥n.\n",
        "- Mes de la campa√±a: Relevante para aprovechar tendencias estacionales.\n",
        "- D√≠as desde el √∫ltimo contacto: Indica la recurrencia y la reciente interacci√≥n.\n",
        "- Pr√©stamo hipotecario: Refleja la carga financiera y la estabilidad del cliente.\n",
        "- Edad: Relacionada con las necesidades y preferencias financieras seg√∫n la etapa de vida.\n",
        "\n",
        "Estos resultados son coherentes con las pr√°cticas comunes en el marketing bancario, donde la comunicaci√≥n efectiva, la situaci√≥n financiera del cliente y la etapa de vida son factores cruciales para el √©xito de las campa√±as.\n",
        "\n",
        "---\n",
        "\n",
        "### ¬øQu√© profundidad y n√∫mero de nodos terminales presenta cada √°rbol? ¬øC√≥mo se relaciona esto con el sobreajuste?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_MsXl1n5uPq",
        "outputId": "c4d50326-54bc-442a-ea42-ec94926714f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Criterio GINI:\n",
            "   Profundidad del √°rbol: 8\n",
            "   N√∫mero de hojas: 143\n",
            "\n",
            "üìä Criterio ENTROPY:\n",
            "   Profundidad del √°rbol: 8\n",
            "   N√∫mero de hojas: 143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for criterio in criterios:\n",
        "  modelos[criterio] = modelo\n",
        "  print(f\"üìä Criterio {criterio.upper()}:\")\n",
        "  print(f\"   Profundidad del √°rbol: {modelo.get_depth()}\")\n",
        "  print(f\"   N√∫mero de hojas: {modelo.get_n_leaves()}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMvrU7KzfT7"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Se encontro la profundidad y numero de hojas.\n",
        "\n",
        "Asimismo, ambos √°rboles tienen la misma profundidad y n√∫mero de hojas. Una profundidad de 8 y 143 hojas son valores moderados que no sugieren sobreajuste. Si los √°rboles fueran m√°s profundos o tuvieran m√°s hojas, podr√≠an capturar ruido en los datos y sobreajustarse. En este caso, los valores actuales parecen equilibrados.\n",
        "\n",
        "---\n",
        "\n",
        "## Optimizaci√≥n del √Årbol\n",
        "###Realiza una b√∫squeda de hiperpar√°metros con GridSearchCV. ¬øQu√© combinaci√≥n ofrece el mejor rendimiento?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJg08vlwTLiF",
        "outputId": "86af60f0-3625-4458-a258-571da6949979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Resultados de optimizaci√≥n:\n",
            "\n",
            "üèÜ Mejor combinaci√≥n:\n",
            "   class_weight: balanced\n",
            "   criterion: gini\n",
            "   max_depth: None\n",
            "   max_features: sqrt\n",
            "   min_samples_leaf: 1\n",
            "   min_samples_split: 2\n",
            "\n",
            "üìà M√©tricas del modelo optimizado:\n",
            "   Precisi√≥n (Accuracy): 0.8389\n",
            "   Recall: 0.5943\n",
            "   F1-Score: 0.5973\n",
            " üí°Precisi√≥n media CV: 0.8337\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# üîß OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS\n",
        "# ==========================================\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "mejor_modelo = grid_search.best_estimator_\n",
        "y_pred_opt = mejor_modelo.predict(X_test)\n",
        "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
        "recall_opt = recall_score(y_test, y_pred_opt, average='macro')  # Macro para evaluar todas las clases por igual\n",
        "f1_opt = f1_score(y_test, y_pred_opt, average='macro')\n",
        "\n",
        "print(\"üîç Resultados de optimizaci√≥n:\")\n",
        "print(\"\\nüèÜ Mejor combinaci√≥n:\")\n",
        "for clave, valor in grid_search.best_params_.items():\n",
        "    print(f\"   {clave}: {valor}\")\n",
        "\n",
        "print(f\"\\nüìà M√©tricas del modelo optimizado:\")\n",
        "print(f\"   Precisi√≥n (Accuracy): {acc_opt:.4f}\")\n",
        "print(f\"   Recall: {recall_opt:.4f}\")\n",
        "print(f\"   F1-Score: {f1_opt:.4f}\")\n",
        "print(f\" üí°Precisi√≥n media CV: {grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzfvvIj0OqW"
      },
      "source": [
        "---\n",
        "\n",
        "### ¬øLa precisi√≥n del √°rbol mejor√≥ significativamente tras la optimizaci√≥n? Justifica si vale la pena el aumento de complejidad\n",
        "\n",
        "La precisi√≥n del √°rbol disminuy√≥ ligeramente tras la optimizaci√≥n, pasando de 0.8583 a 0.8389. Aunque el modelo optimizado muestra una precisi√≥n media en validaci√≥n cruzada de 0.8337, lo que indica una generalizaci√≥n mejor, el recall y el F1-score tambi√©n disminuyeron. Dado que la complejidad del modelo no aument√≥ significativamente, pero el rendimiento general se mantuvo similar o incluso disminuy√≥, no parece que valga la pena el aumento de complejidad. En este caso, ser√≠a recomendable explorar otras opciones de hiperpar√°metros o incluso probar otros algoritmos de modelado para encontrar una soluci√≥n m√°s efectiva.\n",
        "\n",
        "---\n",
        "\n",
        "## M√©todos de Ensamblado\n",
        "\n",
        "### Compara los siguientes modelos en cuanto a precisi√≥n, recall, F1-score y AUC-ROC:\n",
        "  - Random Forest\n",
        "  - Gradient Boosting\n",
        "  - AdaBoost\n",
        "  - Extra Trees\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2EqBHkM5ZUy",
        "outputId": "331b8f5d-a926-44ba-f465-8a24cef2cc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üå≤ RANDOM FOREST\n",
            "Precisi√≥n: 0.8938\n",
            "AUC-ROC: 0.7880\n",
            "\n",
            "‚ö° GRADIENT BOOSTING\n",
            "Precisi√≥n: 0.8932\n",
            "AUC-ROC: 0.7949\n",
            "\n",
            "üéØ ADABOOST\n",
            "Precisi√≥n: 0.8909\n",
            "AUC-ROC: 0.7744\n",
            "\n",
            "üåø EXTRA TREES\n",
            "Precisi√≥n: 0.8941\n",
            "AUC-ROC: 0.7842\n",
            "\n",
            "üìä COMPARACI√ìN FINAL DE TODOS LOS M√âTODOS:\n",
            "                   Precisi√≥n  AUC-ROC\n",
            "Random Forest         0.8938   0.7880\n",
            "Gradient Boosting     0.8932   0.7949\n",
            "AdaBoost              0.8909   0.7744\n",
            "Extra Trees           0.8941   0.7842\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# RANDOM FOREST\n",
        "# ================================\n",
        "\n",
        "print(\"\\nüå≤ RANDOM FOREST\")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2,\n",
        "    max_features='sqrt', bootstrap=True, n_jobs=-1, random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)  # Entrenar modelo\n",
        "y_pred_rf = rf.predict(X_test)  # Predecir\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)  # Calcular precisi√≥n\n",
        "auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])  # Calcular AUC\n",
        "print(f\"Precisi√≥n: {acc_rf:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_rf:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# GRADIENT BOOSTING\n",
        "# ================================\n",
        "\n",
        "print(\"\\n‚ö° GRADIENT BOOSTING\")\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=4,\n",
        "    min_samples_split=10, min_samples_leaf=5,\n",
        "    subsample=0.8, random_state=42\n",
        ")\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
        "auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisi√≥n: {acc_gb:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_gb:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# ADABOOST\n",
        "# ================================\n",
        "\n",
        "print(\"\\nüéØ ADABOOST\")\n",
        "ada = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=100, learning_rate=1.0,\n",
        "    # Cambiar 'SAMME.R' a 'SAMME' ya que 'SAMME.R' no es un valor v√°lido en esta versi√≥n de scikit-learn\n",
        "    algorithm='SAMME',\n",
        "    random_state=42\n",
        ")\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred_ada = ada.predict(X_test)\n",
        "acc_ada = accuracy_score(y_test, y_pred_ada)\n",
        "auc_ada = roc_auc_score(y_test, ada.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisi√≥n: {acc_ada:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_ada:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# EXTRA TREES\n",
        "# ================================\n",
        "\n",
        "print(\"\\nüåø EXTRA TREES\")\n",
        "et = ExtraTreesClassifier(\n",
        "    n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=2,\n",
        "    max_features='sqrt', bootstrap=False, n_jobs=-1, random_state=42\n",
        ")\n",
        "et.fit(X_train, y_train)\n",
        "y_pred_et = et.predict(X_test)\n",
        "acc_et = accuracy_score(y_test, y_pred_et)\n",
        "auc_et = roc_auc_score(y_test, et.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisi√≥n: {acc_et:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_et:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# COMPARACI√ìN DE TODOS LOS MODELOS\n",
        "# ================================\n",
        "\n",
        "# Crear diccionario de resultados\n",
        "resultados = {\n",
        "    'Random Forest': {'Precisi√≥n': acc_rf, 'AUC-ROC': auc_rf},\n",
        "    'Gradient Boosting': {'Precisi√≥n': acc_gb, 'AUC-ROC': auc_gb},\n",
        "    'AdaBoost': {'Precisi√≥n': acc_ada, 'AUC-ROC': auc_ada},\n",
        "    'Extra Trees': {'Precisi√≥n': acc_et, 'AUC-ROC': auc_et}\n",
        "}\n",
        "\n",
        "# Mostrar resultados como DataFrame\n",
        "resultados_df = pd.DataFrame(resultados).T\n",
        "print(\"\\nüìä COMPARACI√ìN FINAL DE TODOS LOS M√âTODOS:\")\n",
        "print(resultados_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxGijon5R_a"
      },
      "source": [
        "---\n",
        "\n",
        "### ¬øQu√© modelo ser√≠a m√°s adecuado para una campa√±a bancaria real que busca minimizar falsos negativos? Justifica tu elecci√≥n.\n",
        "\n",
        "Dado que la campa√±a bancaria busca minimizar falsos negativos, es crucial elegir un modelo que tenga un buen recall, ya que los falsos negativos se relacionan directamente con la capacidad de detectar correctamente las suscripciones positivas. En este caso, aunque los modelos tienen precisiones similares, el Gradient Boosting tiene el mejor AUC-ROC (0.7949), lo que indica una mejor capacidad para distinguir entre las clases. Adem√°s, un buen AUC-ROC sugiere que el modelo puede manejar mejor el trade-off entre recall y precisi√≥n. Por lo tanto, el Gradient Boosting ser√≠a el m√°s adecuado para esta campa√±a, ya que puede ofrecer un mejor equilibrio entre minimizar falsos negativos y mantener un buen rendimiento general.\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretaci√≥n de variables\n",
        "\n",
        "### Extrae las variables m√°s importantes de al menos dos modelos ensamblados. ¬øQu√© patrones o perfiles de cliente parecen m√°s propensos a contratar el dep√≥sito?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVIJv3gMVz83",
        "outputId": "6b01f7fb-829e-4bba-a23d-80ddbd965159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîç Top 10 variables m√°s importantes - Gradient Boosting\n",
            "Variable  Importancia\n",
            "poutcome     0.203162\n",
            "   month     0.154752\n",
            "     age     0.129830\n",
            "   pdays     0.124817\n",
            " balance     0.086611\n",
            " housing     0.078984\n",
            "previous     0.049374\n",
            " contact     0.048357\n",
            "     job     0.036352\n",
            "campaign     0.032749\n",
            "\n",
            "üîç Top 10 variables m√°s importantes - Random forest\n",
            "Variable  Importancia\n",
            "   month     0.213941\n",
            "   pdays     0.186964\n",
            "poutcome     0.166115\n",
            "     age     0.140360\n",
            " balance     0.081331\n",
            " contact     0.062937\n",
            " housing     0.056797\n",
            "previous     0.023031\n",
            "campaign     0.020020\n",
            "     job     0.015420\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Primero optemos las varibales de Gradient Boosting\n",
        "importancia_gb = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Importancia': gb.feature_importances_\n",
        "}).sort_values(by='Importancia', ascending=False).head(10)\n",
        "\n",
        "# Luego , obtengo la importancia de variables de Random forest\n",
        "importancia_ada = pd.DataFrame({\n",
        "    'Variable': X.columns,  # Nombre de las variables (columnas del dataset)\n",
        "    'Importancia': rf.feature_importances_  # Importancia calculada por el modelo\n",
        "}).sort_values(by='Importancia', ascending=False).head(10)  # Ordeno de mayor a menor y me quedo con las 10 principales\n",
        "\n",
        "# Finalmente, imprimo los resultados de forma textual (sin gr√°ficos) para poder analizarlos con facilidad\n",
        "print(\"\\nüîç Top 10 variables m√°s importantes - Gradient Boosting\")\n",
        "print(importancia_ada.to_string(index=False))\n",
        "\n",
        "print(\"\\nüîç Top 10 variables m√°s importantes - Random forest\")\n",
        "print(importancia_gb.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYh_UeJ_9-ZE"
      },
      "source": [
        "#### Repuesta\n",
        "\n",
        "Con nuestra respuesta anterior elegimos nuestra mejor opcion Gradient Boosting y Random forest\n",
        "\n",
        "- poutcome: Ambos modelos coinciden en que el resultado de campa√±as anteriores es muy importante. Clientes que han respondido positivamente en el pasado son m√°s propensos a contratar nuevos productos.\n",
        "- month: El mes de la campa√±a es crucial, sugiriendo que ciertos meses pueden ser m√°s propicios para las campa√±as de marketing.\n",
        "- age: La edad es un factor importante, indicando que ciertas etapas de la vida pueden estar m√°s dispuestas a contratar productos financieros.\n",
        "- pdays: La recurrencia y la reciente interacci√≥n son relevantes. Clientes contactados recientemente pueden estar m√°s dispuestos a considerar una oferta.\n",
        "- balance: Un saldo anual m√°s alto puede indicar una capacidad financiera mayor, lo que puede hacer que los clientes sean m√°s propensos a contratar productos de ahorro.\n",
        "- housing: Tener un pr√©stamo hipotecario puede indicar una situaci√≥n financiera estable, lo que puede hacer que los clientes sean m√°s propensos a considerar productos adicionales.\n",
        "\n",
        "\n",
        "Los clientes m√°s propensos a contratar el dep√≥sito son aquellos que han respondido positivamente a campa√±as anteriores, han sido contactados recientemente, tienen una edad avanzada, y tienen una situaci√≥n financiera estable (alto saldo y pr√©stamos hipotecarios).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Interpretaciones finales\n",
        "## Para concluir el laboratorio, reflexiona y responde:\n",
        "  - ¬øQu√© fortalezas y debilidades identificas en los modelos basados en √°rboles para este tipo de tarea?\n",
        "  - ¬øQu√© modelo aplicar√≠as si tuvieras que entregar una soluci√≥n a un equipo de marketing no t√©cnico? ¬øPor qu√©?\n",
        "  - ¬øQu√© problemas √©ticos o de sesgo podr√≠an surgir al usar estos modelos para tomar decisiones comerciales automatizadas?\n",
        "  - ¬øC√≥mo cambiar√≠a tu estrategia si el dataset estuviera a√∫n m√°s desbalanceado o si faltaran datos en variables clave?\n",
        "\n",
        "\n",
        "Los modelos basados en √°rboles tienen fortalezas como su capacidad para manejar variables categ√≥ricas y num√©ricas sin normalizaci√≥n, y son f√°ciles de interpretar, lo que es √∫til para equipos no t√©cnicos. Sin embargo, pueden sufrir de sobreajuste y ser menos robustos a datos ruidosos. Para un equipo de marketing no t√©cnico, aplicar√≠a un modelo de Random Forest debido a su equilibrio entre precisi√≥n y facilidad de interpretaci√≥n, y porque puede manejar bien datos desbalanceados. Al usar estos modelos, podr√≠an surgir problemas √©ticos como sesgos en la toma de decisiones si los datos de entrenamiento no son representativos de toda la poblaci√≥n. Si el dataset estuviera m√°s desbalanceado, considerar√≠a t√©cnicas de re-muestreo o ajuste de pesos de clase. Si faltaran datos en variables clave, explorar√≠a imputaci√≥n de datos o selecci√≥n de caracter√≠sticas para reducir la dependencia de esas variables.\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
