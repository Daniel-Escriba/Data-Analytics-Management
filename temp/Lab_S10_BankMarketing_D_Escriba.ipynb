{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlBEK-jxPElT"
      },
      "source": [
        "# LABORATORIO: Análisis Comparativo de Árboles de Decisión y Métodos de Ensamblado en Campañas de Marketing Bancario\n",
        "\n",
        "# Introducción al caso\n",
        "\n",
        "En el contexto actual de digitalización financiera, los bancos buscan optimizar sus campañas de marketing directo para aumentar la tasa de conversión de sus productos. Este laboratorio simula el rol de un analista de datos en una institución financiera que busca predecir si un cliente contratará un depósito a plazo fijo a partir de sus características personales, historial financiero y comportamiento previo con el banco.\n",
        "\n",
        "Se utilizará el dataset Bank Marketing, proveniente de campañas telefónicas reales realizadas en Portugal, y se pondrá en práctica una comparación entre modelos de árboles de decisión simples ydiferentes métodos de ensamblado.\n",
        "\n",
        "# Objetivos del laboratorio\n",
        "\n",
        "• Preprocesar adecuadamente un conjunto de datos mixto (numérico y categórico).\n",
        "• Entrenar y comparar modelos de clasificación basados en árboles de decisión y ensamblado.\n",
        "• Aplicar técnicas de evaluación apropiadas para contextos de desbalance de clases.\n",
        "• Interpretar los resultados obtenidos desde un enfoque técnico y comercial.\n",
        "• Reflexionar sobre la aplicabilidad, limitaciones y ética del uso de modelos automatizados en\n",
        "decisiones comerciales.\n",
        "\n",
        " # Preparacion de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oll2aeTNe3I3"
      },
      "source": [
        "## Bank Marketing\n",
        "\n",
        "\n",
        "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable `y`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ywneN0qdP8K",
        "outputId": "74b22b79-f634-4d71-d590-68340932e7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# 1. IMPORTACIÓN DE LIBRERÍAS\n",
        "# =============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wnM-qtkdz0O",
        "outputId": "e0b51c2b-1cbc-4168-9eec-b5fec88f17da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribución de clases (no = no se suscribe, yes = si se suscribe):\n",
            "y\n",
            "no     39922\n",
            "yes     5289\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "y\n",
            "no     0.883015\n",
            "yes    0.116985\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "\n",
            "\n",
            "Mapeo para job: {'admin.': np.int64(0), 'blue-collar': np.int64(1), 'entrepreneur': np.int64(2), 'housemaid': np.int64(3), 'management': np.int64(4), 'retired': np.int64(5), 'self-employed': np.int64(6), 'services': np.int64(7), 'student': np.int64(8), 'technician': np.int64(9), 'unemployed': np.int64(10), 'unknown': np.int64(11)}\n",
            "Mapeo para marital: {'divorced': np.int64(0), 'married': np.int64(1), 'single': np.int64(2)}\n",
            "Mapeo para education: {'primary': np.int64(0), 'secondary': np.int64(1), 'tertiary': np.int64(2), 'unknown': np.int64(3)}\n",
            "Mapeo para default: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para housing: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para loan: {'no': np.int64(0), 'yes': np.int64(1)}\n",
            "Mapeo para contact: {'cellular': np.int64(0), 'telephone': np.int64(1), 'unknown': np.int64(2)}\n",
            "Mapeo para month: {'apr': np.int64(0), 'aug': np.int64(1), 'dec': np.int64(2), 'feb': np.int64(3), 'jan': np.int64(4), 'jul': np.int64(5), 'jun': np.int64(6), 'mar': np.int64(7), 'may': np.int64(8), 'nov': np.int64(9), 'oct': np.int64(10), 'sep': np.int64(11)}\n",
            "Mapeo para poutcome: {'failure': np.int64(0), 'other': np.int64(1), 'success': np.int64(2), 'unknown': np.int64(3)}\n"
          ]
        }
      ],
      "source": [
        "# ===========================================\n",
        "# 2. CARGA DE DATOS\n",
        "# ===========================================\n",
        "\n",
        "# Cargar dataset desde ucirepo\n",
        "# fetch dataset\n",
        "bank_marketing = fetch_ucirepo(id=222)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = bank_marketing.data.features\n",
        "y = bank_marketing.data.targets\n",
        "\n",
        "df = pd.concat([X, y], axis=1)\n",
        "\n",
        "# Ver distribución de clases\n",
        "print(\"\\nDistribución de clases (no = no se suscribe, yes = si se suscribe):\")\n",
        "print(df['y'].value_counts())\n",
        "print(\"\\n\")\n",
        "print(df['y'].value_counts(normalize=True))\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# 4. PREPROCESAMIENTO\n",
        "# ===========================\n",
        "\n",
        "# Guardamos \"y\" como objetivo\n",
        "y = df['y'].map({'no': 0, 'yes': 1})\n",
        "\n",
        "# Eliminamos y del DataFrame para procesar solo características\n",
        "X = df.drop(columns=['y'])\n",
        "\n",
        "#En base al laboratorio anterior, Eliminamos por irrelevancia o sesgo predictivo:\n",
        "#day_of_week: poco predictivo\n",
        "#duration: muy predictiva pero solo se conoce después de llamar , por lo tanto, para un modelo realista, debe eliminarse\n",
        "\n",
        "X = X.drop(columns=['day_of_week', 'duration'], errors='ignore')\n",
        "\n",
        "# Identificamos las columnas categóricas\n",
        "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Primero, vamos a manejar los valores NaN en columnas categóricas\n",
        "# Podemos reemplazarlos con 'unknown' o la moda\n",
        "for col in categorical_columns:\n",
        "    X[col] = X[col].fillna('unknown')\n",
        "\n",
        "# Aplicamos Label Encoding a todas las columnas categóricas\n",
        "label_encoders = {}\n",
        "for column in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "    label_encoders[column] = le\n",
        "    print(f\"Mapeo para {column}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
        "\n",
        "# Manejamos los valores NaN en columnas numéricas\n",
        "numeric_columns = X.select_dtypes(include=['number']).columns.tolist()\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X[numeric_columns] = imputer.fit_transform(X[numeric_columns])\n",
        "\n",
        "# Detectar automáticamente las categóricas (ya excluimos 'y')\n",
        "cat_vars = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Definir el preprocesador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_vars),\n",
        "        # Puedes agregar escalado si lo necesitas más adelante\n",
        "    ],\n",
        "    remainder='passthrough'  # deja pasar otras columnas sin cambios\n",
        ")\n",
        "\n",
        "# Aplicar transformación\n",
        "X_encoded = preprocessor.fit_transform(X)\n",
        "\n",
        "# Estandarizar los datos: necesario porque las variables tienen diferentes escalas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# División entrenamiento-prueba con estratificación (mantiene proporción de clases)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzYCEvV3_bfs"
      },
      "source": [
        "---\n",
        "\n",
        "# Preguntas para desarrollo\n",
        "\n",
        "## Árboles de Decisión\n",
        "\n",
        "### ¿Qué criterio de división (gini, entropy) ofrece mejor precisión, recall o F1-score en este caso?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxEdDsDhLffq",
        "outputId": "ee12a066-d7b4-4f49-863b-cb02a4839165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌳 COMPARACIÓN DE CRITERIOS DE DIVISIÓN\n",
            "==================================================\n",
            "📊 Criterio GINI:\n",
            "   Precisión: 0.8583\n",
            "   Recall: 0.6923\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.93      0.91      0.92      7985\n",
            "         yes       0.41      0.48      0.44      1058\n",
            "\n",
            "    accuracy                           0.86      9043\n",
            "   macro avg       0.67      0.69      0.68      9043\n",
            "weighted avg       0.87      0.86      0.86      9043\n",
            "\n",
            "\n",
            "📊 Criterio ENTROPY:\n",
            "   Precisión: 0.8628\n",
            "   Recall: 0.6882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.93      0.92      0.92      7985\n",
            "         yes       0.42      0.46      0.44      1058\n",
            "\n",
            "    accuracy                           0.86      9043\n",
            "   macro avg       0.67      0.69      0.68      9043\n",
            "weighted avg       0.87      0.86      0.87      9043\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 🌳 COMPARACIÓN DE CRITERIOS DE DIVISIÓN\n",
        "# ==========================================\n",
        "\n",
        "criterios = ['gini', 'entropy']\n",
        "modelos = {}\n",
        "\n",
        "print(\"\\n🌳 COMPARACIÓN DE CRITERIOS DE DIVISIÓN\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for criterio in criterios:\n",
        "    modelo = DecisionTreeClassifier(\n",
        "        criterion=criterio,\n",
        "        max_depth=8,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=5,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    modelos[criterio] = modelo\n",
        "\n",
        "    print(f\"📊 Criterio {criterio.upper()}:\")\n",
        "    print(f\"   Precisión: {accuracy:.4f}\")\n",
        "    print(f\"   Recall: {recall:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"no\", \"yes\"]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Mt4Ob9_-zU"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Precisión:\n",
        "- ENTROPY ofrece una mejor precisión general (0.8628) en comparación con GINI (0.8583). Aunque la diferencia es pequeña, ENTROPY tiene una ligera ventaja en la precisión general del modelo.\n",
        "\n",
        "Recall:\n",
        "- GINI tiene un mejor recall general (0.6923) en comparación con ENTROPY (0.6882). Sin embargo, en detalle, para la clase \"yes\" (suscripciones logradas), ENTROPY tiene un recall de 0.46, mientras que GINI tiene un recall de 0.48. Esto indica que ambos criterios tienen dificultades para detectar bien la clase \"yes\", aunque GINI es ligeramente mejor en este aspecto.\n",
        "\n",
        "F1-score:\n",
        "- El F1-score ponderado es muy similar entre ambos criterios, con ENTROPY ligeramente mejor (0.87) en comparación con GINI (0.86). Esto confirma que el equilibrio entre precisión y recall es similar en ambos casos.\n",
        "\n",
        "**Conclusión:**\n",
        "\n",
        "Si bien ambos criterios de división (GINI y ENTROPY) ofrecen resultados muy similares, ENTROPY tiene una ligera ventaja en términos de precisión general y F1-score ponderado. Sin embargo, GINI tiene un mejor recall general, aunque la diferencia es mínima.\n",
        "\n",
        "En general, ninguno de los criterios alcanza un estado óptimo, especialmente en la detección de la clase \"yes\". Por lo tanto, aunque ENTROPY tiene una ligera ventaja en precisión y F1-score, ambos criterios necesitan mejorar para alcanzar una optimización mejor en la detección de ambas clases.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Analiza el árbol obtenido: ¿qué variables aparecen como más importantes? ¿Son coherentes con el contexto del marketing bancario?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaG-laQ8NB9G",
        "outputId": "9fb47802-7cc4-47ad-d0a6-d97eff240825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Variables más importantes según el árbol GINI:\n",
            "   Variable  Importancia\n",
            "8   contact     0.272957\n",
            "9     month     0.201860\n",
            "11    pdays     0.144226\n",
            "6   housing     0.113830\n",
            "0       age     0.086976\n",
            "\n",
            "🔍 Variables más importantes según el árbol ENTROPY:\n",
            "   Variable  Importancia\n",
            "8   contact     0.249110\n",
            "9     month     0.195391\n",
            "11    pdays     0.151103\n",
            "6   housing     0.100921\n",
            "0       age     0.083624\n"
          ]
        }
      ],
      "source": [
        "for criterio in criterios:\n",
        "    modelo = modelos[criterio]\n",
        "\n",
        "    # Obtener importancias de las variables del modelo entrenado\n",
        "    importancias = modelo.feature_importances_\n",
        "\n",
        "    # Crear un DataFrame con nombres de las variables e importancias\n",
        "    importancias_df = pd.DataFrame({\n",
        "        'Variable': X.columns,\n",
        "        'Importancia': importancias\n",
        "    }).sort_values(by='Importancia', ascending=False)\n",
        "\n",
        "    # Mostrar las 5 variables más importantes\n",
        "    print(f\"\\n🔍 Variables más importantes según el árbol {criterio.upper()}:\")\n",
        "    print(importancias_df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R2EJzPWHHvf"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Las variables más importantes según los árboles GINI y ENTROPY son consistentes con el contexto del marketing bancario. Estas variables reflejan aspectos clave que pueden influir en la respuesta de los clientes a una campaña de marketing:\n",
        "\n",
        "- Tipo de contacto: Importante para la efectividad de la comunicación.\n",
        "- Mes de la campaña: Relevante para aprovechar tendencias estacionales.\n",
        "- Días desde el último contacto: Indica la recurrencia y la reciente interacción.\n",
        "- Préstamo hipotecario: Refleja la carga financiera y la estabilidad del cliente.\n",
        "- Edad: Relacionada con las necesidades y preferencias financieras según la etapa de vida.\n",
        "\n",
        "Estos resultados son coherentes con las prácticas comunes en el marketing bancario, donde la comunicación efectiva, la situación financiera del cliente y la etapa de vida son factores cruciales para el éxito de las campañas.\n",
        "\n",
        "---\n",
        "\n",
        "### ¿Qué profundidad y número de nodos terminales presenta cada árbol? ¿Cómo se relaciona esto con el sobreajuste?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_MsXl1n5uPq",
        "outputId": "c4d50326-54bc-442a-ea42-ec94926714f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Criterio GINI:\n",
            "   Profundidad del árbol: 8\n",
            "   Número de hojas: 143\n",
            "\n",
            "📊 Criterio ENTROPY:\n",
            "   Profundidad del árbol: 8\n",
            "   Número de hojas: 143\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for criterio in criterios:\n",
        "  modelos[criterio] = modelo\n",
        "  print(f\"📊 Criterio {criterio.upper()}:\")\n",
        "  print(f\"   Profundidad del árbol: {modelo.get_depth()}\")\n",
        "  print(f\"   Número de hojas: {modelo.get_n_leaves()}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMvrU7KzfT7"
      },
      "source": [
        "#### Respuesta\n",
        "\n",
        "Se encontro la profundidad y numero de hojas.\n",
        "\n",
        "Asimismo, ambos árboles tienen la misma profundidad y número de hojas. Una profundidad de 8 y 143 hojas son valores moderados que no sugieren sobreajuste. Si los árboles fueran más profundos o tuvieran más hojas, podrían capturar ruido en los datos y sobreajustarse. En este caso, los valores actuales parecen equilibrados.\n",
        "\n",
        "---\n",
        "\n",
        "## Optimización del Árbol\n",
        "###Realiza una búsqueda de hiperparámetros con GridSearchCV. ¿Qué combinación ofrece el mejor rendimiento?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJg08vlwTLiF",
        "outputId": "86af60f0-3625-4458-a258-571da6949979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Resultados de optimización:\n",
            "\n",
            "🏆 Mejor combinación:\n",
            "   class_weight: balanced\n",
            "   criterion: gini\n",
            "   max_depth: None\n",
            "   max_features: sqrt\n",
            "   min_samples_leaf: 1\n",
            "   min_samples_split: 2\n",
            "\n",
            "📈 Métricas del modelo optimizado:\n",
            "   Precisión (Accuracy): 0.8389\n",
            "   Recall: 0.5943\n",
            "   F1-Score: 0.5973\n",
            " 💡Precisión media CV: 0.8337\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 🔧 OPTIMIZACIÓN DE HIPERPARÁMETROS\n",
        "# ==========================================\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, 10, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "mejor_modelo = grid_search.best_estimator_\n",
        "y_pred_opt = mejor_modelo.predict(X_test)\n",
        "acc_opt = accuracy_score(y_test, y_pred_opt)\n",
        "recall_opt = recall_score(y_test, y_pred_opt, average='macro')  # Macro para evaluar todas las clases por igual\n",
        "f1_opt = f1_score(y_test, y_pred_opt, average='macro')\n",
        "\n",
        "print(\"🔍 Resultados de optimización:\")\n",
        "print(\"\\n🏆 Mejor combinación:\")\n",
        "for clave, valor in grid_search.best_params_.items():\n",
        "    print(f\"   {clave}: {valor}\")\n",
        "\n",
        "print(f\"\\n📈 Métricas del modelo optimizado:\")\n",
        "print(f\"   Precisión (Accuracy): {acc_opt:.4f}\")\n",
        "print(f\"   Recall: {recall_opt:.4f}\")\n",
        "print(f\"   F1-Score: {f1_opt:.4f}\")\n",
        "print(f\" 💡Precisión media CV: {grid_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzfvvIj0OqW"
      },
      "source": [
        "---\n",
        "\n",
        "### ¿La precisión del árbol mejoró significativamente tras la optimización? Justifica si vale la pena el aumento de complejidad\n",
        "\n",
        "La precisión del árbol disminuyó ligeramente tras la optimización, pasando de 0.8583 a 0.8389. Aunque el modelo optimizado muestra una precisión media en validación cruzada de 0.8337, lo que indica una generalización mejor, el recall y el F1-score también disminuyeron. Dado que la complejidad del modelo no aumentó significativamente, pero el rendimiento general se mantuvo similar o incluso disminuyó, no parece que valga la pena el aumento de complejidad. En este caso, sería recomendable explorar otras opciones de hiperparámetros o incluso probar otros algoritmos de modelado para encontrar una solución más efectiva.\n",
        "\n",
        "---\n",
        "\n",
        "## Métodos de Ensamblado\n",
        "\n",
        "### Compara los siguientes modelos en cuanto a precisión, recall, F1-score y AUC-ROC:\n",
        "  - Random Forest\n",
        "  - Gradient Boosting\n",
        "  - AdaBoost\n",
        "  - Extra Trees\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2EqBHkM5ZUy",
        "outputId": "331b8f5d-a926-44ba-f465-8a24cef2cc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌲 RANDOM FOREST\n",
            "Precisión: 0.8938\n",
            "AUC-ROC: 0.7880\n",
            "\n",
            "⚡ GRADIENT BOOSTING\n",
            "Precisión: 0.8932\n",
            "AUC-ROC: 0.7949\n",
            "\n",
            "🎯 ADABOOST\n",
            "Precisión: 0.8909\n",
            "AUC-ROC: 0.7744\n",
            "\n",
            "🌿 EXTRA TREES\n",
            "Precisión: 0.8941\n",
            "AUC-ROC: 0.7842\n",
            "\n",
            "📊 COMPARACIÓN FINAL DE TODOS LOS MÉTODOS:\n",
            "                   Precisión  AUC-ROC\n",
            "Random Forest         0.8938   0.7880\n",
            "Gradient Boosting     0.8932   0.7949\n",
            "AdaBoost              0.8909   0.7744\n",
            "Extra Trees           0.8941   0.7842\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# RANDOM FOREST\n",
        "# ================================\n",
        "\n",
        "print(\"\\n🌲 RANDOM FOREST\")\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=10, min_samples_split=5, min_samples_leaf=2,\n",
        "    max_features='sqrt', bootstrap=True, n_jobs=-1, random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)  # Entrenar modelo\n",
        "y_pred_rf = rf.predict(X_test)  # Predecir\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)  # Calcular precisión\n",
        "auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])  # Calcular AUC\n",
        "print(f\"Precisión: {acc_rf:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_rf:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# GRADIENT BOOSTING\n",
        "# ================================\n",
        "\n",
        "print(\"\\n⚡ GRADIENT BOOSTING\")\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=4,\n",
        "    min_samples_split=10, min_samples_leaf=5,\n",
        "    subsample=0.8, random_state=42\n",
        ")\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
        "auc_gb = roc_auc_score(y_test, gb.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisión: {acc_gb:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_gb:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# ADABOOST\n",
        "# ================================\n",
        "\n",
        "print(\"\\n🎯 ADABOOST\")\n",
        "ada = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=100, learning_rate=1.0,\n",
        "    # Cambiar 'SAMME.R' a 'SAMME' ya que 'SAMME.R' no es un valor válido en esta versión de scikit-learn\n",
        "    algorithm='SAMME',\n",
        "    random_state=42\n",
        ")\n",
        "ada.fit(X_train, y_train)\n",
        "y_pred_ada = ada.predict(X_test)\n",
        "acc_ada = accuracy_score(y_test, y_pred_ada)\n",
        "auc_ada = roc_auc_score(y_test, ada.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisión: {acc_ada:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_ada:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# EXTRA TREES\n",
        "# ================================\n",
        "\n",
        "print(\"\\n🌿 EXTRA TREES\")\n",
        "et = ExtraTreesClassifier(\n",
        "    n_estimators=200, max_depth=None, min_samples_split=5, min_samples_leaf=2,\n",
        "    max_features='sqrt', bootstrap=False, n_jobs=-1, random_state=42\n",
        ")\n",
        "et.fit(X_train, y_train)\n",
        "y_pred_et = et.predict(X_test)\n",
        "acc_et = accuracy_score(y_test, y_pred_et)\n",
        "auc_et = roc_auc_score(y_test, et.predict_proba(X_test)[:, 1])\n",
        "print(f\"Precisión: {acc_et:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_et:.4f}\")\n",
        "\n",
        "# ================================\n",
        "# COMPARACIÓN DE TODOS LOS MODELOS\n",
        "# ================================\n",
        "\n",
        "# Crear diccionario de resultados\n",
        "resultados = {\n",
        "    'Random Forest': {'Precisión': acc_rf, 'AUC-ROC': auc_rf},\n",
        "    'Gradient Boosting': {'Precisión': acc_gb, 'AUC-ROC': auc_gb},\n",
        "    'AdaBoost': {'Precisión': acc_ada, 'AUC-ROC': auc_ada},\n",
        "    'Extra Trees': {'Precisión': acc_et, 'AUC-ROC': auc_et}\n",
        "}\n",
        "\n",
        "# Mostrar resultados como DataFrame\n",
        "resultados_df = pd.DataFrame(resultados).T\n",
        "print(\"\\n📊 COMPARACIÓN FINAL DE TODOS LOS MÉTODOS:\")\n",
        "print(resultados_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gxGijon5R_a"
      },
      "source": [
        "---\n",
        "\n",
        "### ¿Qué modelo sería más adecuado para una campaña bancaria real que busca minimizar falsos negativos? Justifica tu elección.\n",
        "\n",
        "Dado que la campaña bancaria busca minimizar falsos negativos, es crucial elegir un modelo que tenga un buen recall, ya que los falsos negativos se relacionan directamente con la capacidad de detectar correctamente las suscripciones positivas. En este caso, aunque los modelos tienen precisiones similares, el Gradient Boosting tiene el mejor AUC-ROC (0.7949), lo que indica una mejor capacidad para distinguir entre las clases. Además, un buen AUC-ROC sugiere que el modelo puede manejar mejor el trade-off entre recall y precisión. Por lo tanto, el Gradient Boosting sería el más adecuado para esta campaña, ya que puede ofrecer un mejor equilibrio entre minimizar falsos negativos y mantener un buen rendimiento general.\n",
        "\n",
        "---\n",
        "\n",
        "## Interpretación de variables\n",
        "\n",
        "### Extrae las variables más importantes de al menos dos modelos ensamblados. ¿Qué patrones o perfiles de cliente parecen más propensos a contratar el depósito?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVIJv3gMVz83",
        "outputId": "6b01f7fb-829e-4bba-a23d-80ddbd965159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Top 10 variables más importantes - Gradient Boosting\n",
            "Variable  Importancia\n",
            "poutcome     0.203162\n",
            "   month     0.154752\n",
            "     age     0.129830\n",
            "   pdays     0.124817\n",
            " balance     0.086611\n",
            " housing     0.078984\n",
            "previous     0.049374\n",
            " contact     0.048357\n",
            "     job     0.036352\n",
            "campaign     0.032749\n",
            "\n",
            "🔍 Top 10 variables más importantes - Random forest\n",
            "Variable  Importancia\n",
            "   month     0.213941\n",
            "   pdays     0.186964\n",
            "poutcome     0.166115\n",
            "     age     0.140360\n",
            " balance     0.081331\n",
            " contact     0.062937\n",
            " housing     0.056797\n",
            "previous     0.023031\n",
            "campaign     0.020020\n",
            "     job     0.015420\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Primero optemos las varibales de Gradient Boosting\n",
        "importancia_gb = pd.DataFrame({\n",
        "    'Variable': X.columns,\n",
        "    'Importancia': gb.feature_importances_\n",
        "}).sort_values(by='Importancia', ascending=False).head(10)\n",
        "\n",
        "# Luego , obtengo la importancia de variables de Random forest\n",
        "importancia_ada = pd.DataFrame({\n",
        "    'Variable': X.columns,  # Nombre de las variables (columnas del dataset)\n",
        "    'Importancia': rf.feature_importances_  # Importancia calculada por el modelo\n",
        "}).sort_values(by='Importancia', ascending=False).head(10)  # Ordeno de mayor a menor y me quedo con las 10 principales\n",
        "\n",
        "# Finalmente, imprimo los resultados de forma textual (sin gráficos) para poder analizarlos con facilidad\n",
        "print(\"\\n🔍 Top 10 variables más importantes - Gradient Boosting\")\n",
        "print(importancia_ada.to_string(index=False))\n",
        "\n",
        "print(\"\\n🔍 Top 10 variables más importantes - Random forest\")\n",
        "print(importancia_gb.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYh_UeJ_9-ZE"
      },
      "source": [
        "#### Repuesta\n",
        "\n",
        "Con nuestra respuesta anterior elegimos nuestra mejor opcion Gradient Boosting y Random forest\n",
        "\n",
        "- poutcome: Ambos modelos coinciden en que el resultado de campañas anteriores es muy importante. Clientes que han respondido positivamente en el pasado son más propensos a contratar nuevos productos.\n",
        "- month: El mes de la campaña es crucial, sugiriendo que ciertos meses pueden ser más propicios para las campañas de marketing.\n",
        "- age: La edad es un factor importante, indicando que ciertas etapas de la vida pueden estar más dispuestas a contratar productos financieros.\n",
        "- pdays: La recurrencia y la reciente interacción son relevantes. Clientes contactados recientemente pueden estar más dispuestos a considerar una oferta.\n",
        "- balance: Un saldo anual más alto puede indicar una capacidad financiera mayor, lo que puede hacer que los clientes sean más propensos a contratar productos de ahorro.\n",
        "- housing: Tener un préstamo hipotecario puede indicar una situación financiera estable, lo que puede hacer que los clientes sean más propensos a considerar productos adicionales.\n",
        "\n",
        "\n",
        "Los clientes más propensos a contratar el depósito son aquellos que han respondido positivamente a campañas anteriores, han sido contactados recientemente, tienen una edad avanzada, y tienen una situación financiera estable (alto saldo y préstamos hipotecarios).\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Interpretaciones finales\n",
        "## Para concluir el laboratorio, reflexiona y responde:\n",
        "  - ¿Qué fortalezas y debilidades identificas en los modelos basados en árboles para este tipo de tarea?\n",
        "  - ¿Qué modelo aplicarías si tuvieras que entregar una solución a un equipo de marketing no técnico? ¿Por qué?\n",
        "  - ¿Qué problemas éticos o de sesgo podrían surgir al usar estos modelos para tomar decisiones comerciales automatizadas?\n",
        "  - ¿Cómo cambiaría tu estrategia si el dataset estuviera aún más desbalanceado o si faltaran datos en variables clave?\n",
        "\n",
        "\n",
        "Los modelos basados en árboles tienen fortalezas como su capacidad para manejar variables categóricas y numéricas sin normalización, y son fáciles de interpretar, lo que es útil para equipos no técnicos. Sin embargo, pueden sufrir de sobreajuste y ser menos robustos a datos ruidosos. Para un equipo de marketing no técnico, aplicaría un modelo de Random Forest debido a su equilibrio entre precisión y facilidad de interpretación, y porque puede manejar bien datos desbalanceados. Al usar estos modelos, podrían surgir problemas éticos como sesgos en la toma de decisiones si los datos de entrenamiento no son representativos de toda la población. Si el dataset estuviera más desbalanceado, consideraría técnicas de re-muestreo o ajuste de pesos de clase. Si faltaran datos en variables clave, exploraría imputación de datos o selección de características para reducir la dependencia de esas variables.\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
